{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport librosa\nimport numpy as np \nimport IPython.display as ipd\nimport librosa.display\nimport matplotlib.pyplot as plt\n# from tqdm import tqdm\nfrom datetime import datetime\nfrom tqdm import tqdm_notebook as tqdm\nfrom tqdm.notebook import tqdm_notebook\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.io import imread, imshow\nimport cv2\n\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import recall_score , classification_report , confusion_matrix  ,roc_curve , roc_auc_score , accuracy_score\nfrom sklearn.metrics import precision_recall_curve , auc ,f1_score , plot_confusion_matrix , precision_score , recall_score\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import normalize\nfrom sklearn.pipeline import make_pipeline\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten, LSTM, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\n# tf.keras.utils.to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-25T10:09:31.568461Z","iopub.execute_input":"2023-01-25T10:09:31.569188Z","iopub.status.idle":"2023-01-25T10:09:31.591744Z","shell.execute_reply.started":"2023-01-25T10:09:31.569150Z","shell.execute_reply":"2023-01-25T10:09:31.590269Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"file_name = []\nlabels = []\ncat = 0\ndog = 1\nfor i in glob.glob('/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat*'+'*/*.jpg'):\n    labels.append(cat)\n    file_name.append(i)\ndf = pd.DataFrame({'FileName':file_name,'Label':labels})\n\nfor i in glob.glob('/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog*'+'*/*.jpg'):\n    labels.append(dog)\n    file_name.append(i)\ndf = pd.DataFrame({'FileName':file_name,'Label':labels})","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:09:32.121286Z","iopub.execute_input":"2023-01-25T10:09:32.121673Z","iopub.status.idle":"2023-01-25T10:09:32.230644Z","shell.execute_reply.started":"2023-01-25T10:09:32.121639Z","shell.execute_reply":"2023-01-25T10:09:32.229416Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:09:34.231070Z","iopub.execute_input":"2023-01-25T10:09:34.232288Z","iopub.status.idle":"2023-01-25T10:09:34.253387Z","shell.execute_reply.started":"2023-01-25T10:09:34.232241Z","shell.execute_reply":"2023-01-25T10:09:34.251825Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"                                                FileName  Label\n0      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n1      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n2      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n3      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n4      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n...                                                  ...    ...\n24995  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n24996  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24997  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24998  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24999  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n\n[25000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FileName</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df=df.sample(800)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T09:56:25.783211Z","iopub.execute_input":"2023-01-25T09:56:25.783666Z","iopub.status.idle":"2023-01-25T09:56:25.791271Z","shell.execute_reply.started":"2023-01-25T09:56:25.783628Z","shell.execute_reply":"2023-01-25T09:56:25.789680Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# df.reset_index(drop = True, inplace = True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:09:57.450084Z","iopub.execute_input":"2023-01-25T10:09:57.451290Z","iopub.status.idle":"2023-01-25T10:09:57.464443Z","shell.execute_reply.started":"2023-01-25T10:09:57.451236Z","shell.execute_reply":"2023-01-25T10:09:57.463350Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"                                                FileName  Label\n0      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n1      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n2      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n3      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n4      /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n...                                                  ...    ...\n24995  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      1\n24996  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24997  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24998  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n24999  /kaggle/input/microsoft-catsvsdogs-dataset/Pet...      0\n\n[25000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FileName</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>/kaggle/input/microsoft-catsvsdogs-dataset/Pet...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features_normal = []\nfor index_num,row in tqdm(df.iterrows()):\n    try:\n        image = cv2.imread(row[0])\n        image = cv2.resize(image,(224,224))\n        image = image.astype('float32')/255\n        features_normal.append(image)\n    except Exception as e:\n        print(e)\n#         pass\n#     break\n#     imshow(image) \n# df['features'] = features_normal","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:10:00.600800Z","iopub.execute_input":"2023-01-25T10:10:00.601282Z","iopub.status.idle":"2023-01-25T10:15:00.259537Z","shell.execute_reply.started":"2023-01-25T10:10:00.601242Z","shell.execute_reply":"2023-01-25T10:15:00.258052Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3abf9d9f12bf446e9fc2c9943838c48d"}},"metadata":{}},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Warning: unknown JFIF revision number 0.00\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nOpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"final_labels = df['Label'][:len(features_normal)]\n# set(final_labels)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:17:00.232831Z","iopub.execute_input":"2023-01-25T10:17:00.233243Z","iopub.status.idle":"2023-01-25T10:17:00.239399Z","shell.execute_reply.started":"2023-01-25T10:17:00.233196Z","shell.execute_reply":"2023-01-25T10:17:00.237607Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"**do this only when we want to use softmax as final output layer in binary classification**","metadata":{}},{"cell_type":"code","source":"# y = tf.keras.utils.to_categorical(np.array(df['Label']),2)\ny = tf.keras.utils.to_categorical(np.array(final_labels),2) #dont rum in sigmoid","metadata":{"execution":{"iopub.status.busy":"2023-01-25T09:58:38.357525Z","iopub.execute_input":"2023-01-25T09:58:38.358886Z","iopub.status.idle":"2023-01-25T09:58:38.364090Z","shell.execute_reply.started":"2023-01-25T09:58:38.358828Z","shell.execute_reply":"2023-01-25T09:58:38.362941Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(np.array(features_normal),np.array(final_labels),test_size=0.2,random_state=0)\n# x_train,x_test,y_train,y_test=train_test_split(np.array(features_normal),np.array(y),test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:17:51.521363Z","iopub.execute_input":"2023-01-25T10:17:51.521830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:03.426774Z","iopub.execute_input":"2023-01-25T10:06:03.427182Z","iopub.status.idle":"2023-01-25T10:06:03.436267Z","shell.execute_reply.started":"2023-01-25T10:06:03.427150Z","shell.execute_reply":"2023-01-25T10:06:03.434988Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"print('x_train shape:', np.array(x_train).shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:08.614673Z","iopub.execute_input":"2023-01-25T10:06:08.615089Z","iopub.status.idle":"2023-01-25T10:06:08.703453Z","shell.execute_reply.started":"2023-01-25T10:06:08.615055Z","shell.execute_reply":"2023-01-25T10:06:08.702107Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"x_train shape: (637, 224, 224, 3)\n637 train samples\n160 test samples\n","output_type":"stream"}]},{"cell_type":"code","source":"np.array(x_train[0]).shape, np.array(x_train[1]).shape","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:14.378652Z","iopub.execute_input":"2023-01-25T10:06:14.379053Z","iopub.status.idle":"2023-01-25T10:06:14.386741Z","shell.execute_reply.started":"2023-01-25T10:06:14.379024Z","shell.execute_reply":"2023-01-25T10:06:14.385471Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"((224, 224, 3), (224, 224, 3))"},"metadata":{}}]},{"cell_type":"code","source":"# dhyan se dekho \n# iss dataset m bas 2 h categories hai \n# isliye last layer m sigmoid ya fir tanh function use karna tha na ki softmax \n# softmax to 3 ya fir usse jada classes vale case m h use karte hai \n# thoda sa dhyan de ki kon sa activation function kiske sath use hoga ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T09:58:59.931717Z","iopub.execute_input":"2023-01-25T09:58:59.932853Z","iopub.status.idle":"2023-01-25T09:58:59.937484Z","shell.execute_reply.started":"2023-01-25T09:58:59.932814Z","shell.execute_reply":"2023-01-25T09:58:59.936275Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu',  input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\n# model.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\n# model.add(Dropout(0.4))\nmodel.add(Dense(1, activation='sigmoid'))\n# model.add(Dense(2, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:52.497547Z","iopub.execute_input":"2023-01-25T10:06:52.497984Z","iopub.status.idle":"2023-01-25T10:06:52.665780Z","shell.execute_reply.started":"2023-01-25T10:06:52.497953Z","shell.execute_reply":"2023-01-25T10:06:52.664305Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_18 (Conv2D)           (None, 224, 224, 16)      208       \n_________________________________________________________________\nmax_pooling2d_18 (MaxPooling (None, 112, 112, 16)      0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 112, 112, 32)      2080      \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 56, 56, 32)        0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 56, 56, 64)        8256      \n_________________________________________________________________\nmax_pooling2d_20 (MaxPooling (None, 28, 28, 64)        0         \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 50176)             0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 500)               25088500  \n_________________________________________________________________\ndense_13 (Dense)             (None, 1)                 501       \n=================================================================\nTotal params: 25,099,545\nTrainable params: 25,099,545\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:55.404492Z","iopub.execute_input":"2023-01-25T10:06:55.405266Z","iopub.status.idle":"2023-01-25T10:06:55.415977Z","shell.execute_reply.started":"2023-01-25T10:06:55.405212Z","shell.execute_reply":"2023-01-25T10:06:55.414725Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"model.load_weights('/kaggle/working/model.weights.best.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint   \n\n# train the model\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n\nhist = model.fit(x_train, y_train, batch_size=32, epochs=10,\n          validation_data=(x_test, y_test), callbacks=[checkpointer], \n          verbose=2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:06:56.794460Z","iopub.execute_input":"2023-01-25T10:06:56.794948Z","iopub.status.idle":"2023-01-25T10:08:10.261356Z","shell.execute_reply.started":"2023-01-25T10:06:56.794910Z","shell.execute_reply":"2023-01-25T10:08:10.260107Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Epoch 1/10\n20/20 - 8s - loss: 0.0000e+00 - accuracy: 0.4474 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00001: val_loss improved from inf to 0.00000, saving model to model.weights.best.hdf5\nEpoch 2/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00002: val_loss did not improve from 0.00000\nEpoch 3/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00003: val_loss did not improve from 0.00000\nEpoch 4/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00004: val_loss did not improve from 0.00000\nEpoch 5/10\n20/20 - 8s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00005: val_loss did not improve from 0.00000\nEpoch 6/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00006: val_loss did not improve from 0.00000\nEpoch 7/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00007: val_loss did not improve from 0.00000\nEpoch 8/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00008: val_loss did not improve from 0.00000\nEpoch 9/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00009: val_loss did not improve from 0.00000\nEpoch 10/10\n20/20 - 7s - loss: 0.0000e+00 - accuracy: 0.4458 - val_loss: 0.0000e+00 - val_accuracy: 0.4812\n\nEpoch 00010: val_loss did not improve from 0.00000\n","output_type":"stream"}]},{"cell_type":"code","source":"test_accuracy=model.evaluate(x_test,np.array(y_test),verbose=0)\nprint(test_accuracy[1]*100)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T10:08:12.685597Z","iopub.execute_input":"2023-01-25T10:08:12.686032Z","iopub.status.idle":"2023-01-25T10:08:13.139112Z","shell.execute_reply.started":"2023-01-25T10:08:12.685999Z","shell.execute_reply":"2023-01-25T10:08:13.137693Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"48.124998807907104\n","output_type":"stream"}]},{"cell_type":"code","source":"# r = image[:,:,0]\n# g = image[:,:,1]\n# b = image[:,:,2]\n\n# # shape = image.shape, features = np.reshape(image,shape)\n# # Visualize the individual color channels\n# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n# ax1.set_title('R channel')\n# ax1.imshow(r)\n# ax2.set_title('G channel')\n# ax2.imshow(g)\n# ax3.set_title('B channel')\n# ax3.imshow(b)","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}